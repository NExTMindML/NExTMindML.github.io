<app-tittle>Rendimiento Bajo</app-tittle>

<app-paragraph>
    El Aprendizaje Automático presenta lo que se llama el "Problema de Generalización".
</app-paragraph>

<app-paragraph>
    El problema de generalización se refiere a qué tan bien se aplican los conceptos aprendidos del modelo de Aprendizaje Automático a ejemplos específicos no vistos por el modelo cuando estaba aprendiendo.
</app-paragraph>

<app-paragraph>
    Así, la causa del rendimiento deficiente está relacionada con este problema de generalización, que se puede dividir en dos tipos: sobreajuste y subajuste.
</app-paragraph>

<app-sub-title>Sobreajuste</app-sub-title>

<app-paragraph>
    El sobreajuste se refiere a aprender tan bien los datos de entrenamiento que no refleja el mismo rendimiento/resultados con los nuevos datos (no generaliza).
</app-paragraph>

<app-paragraph>
    Este es el problema más común presente en la práctica y es más un problema para los algoritmos no paramétricos, que tienen más flexibilidad al aprender la función objetivo.
</app-paragraph>

<app-paragraph>
    Este tipo de problema se puede limitar con conjuntos de datos de validación y mediante el uso de técnicas de remuestreo.
</app-paragraph>

<app-sub-title>Subajuste</app-sub-title>

<app-paragraph>
    El subajuste se refiere a la incapacidad de aprender correctamente el problema a partir de los datos de entrenamiento, por lo que es fácil de detectar.
</app-paragraph>

<app-paragraph>
    La solución a este tipo de problema es alternar entre los algoritmos de Aprendizaje Automático utilizados.
</app-paragraph>

<app-sub-title>Punto Óptimo</app-sub-title>

<app-paragraph>
    Idealmente, en la práctica, debería haber un equilibrio entre el sobreajuste y el subajuste, por lo que se debe tener en cuenta el punto óptimo (el punto de equilibrio).
</app-paragraph>

<app-paragraph>
    El punto óptimo es el punto anterior donde el error en los datos de entrenamiento comienza a aumentar si el modelo tiene buenas habilidades en los datos de entrenamiento y los nuevos datos.
</app-paragraph>

<app-sub-title>Resumen</app-sub-title>

<app-paragraph>En esta sección vimos:
</app-paragraph>

<ul>
    <app-list-item>
        Sobreajuste: Buen rendimiento en los datos de entrenamiento, pero mala generalización en los nuevos datos que se aplican.
    </app-list-item>

    <app-list-item>
        Subajuste: Mal rendimiento en los datos de entrenamiento y mala generalización en los nuevos datos aplicados.
    </app-list-item>

    <app-list-item>
        Punto óptimo: el punto de equilibrio óptimo en el cual un modelo de aprendizaje funciona de manera más eficiente y efectiva.
    </app-list-item>
</ul>
