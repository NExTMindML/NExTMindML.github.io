<app-tittle>Titanic</app-tittle>

<app-sub-title>Introducción</app-sub-title>

<app-paragraph>¡Hola! En esta sección iremos paso a paso a través del proceso de construir un algoritmo de Machine Learning dedicado a predecir la supervivencia de cada pasajero del Titanic.</app-paragraph>

<app-paragraph>Para lograr este objetivo final, pasaremos por ciertas etapas siguiendo el "Cross Industry Standard Process for Data Mining" o, en otras palabras, el CRISP-DM. Así que, a modo de resumen, veremos lo siguiente:</app-paragraph>

<ul>
    <app-list-item>Entender el negocio y los datos.</app-list-item>
    <app-list-item>Preparación de datos.</app-list-item>
    <app-list-item>Modelado.</app-list-item>
    <app-list-item>Evaluación.</app-list-item>
</ul>

<app-paragraph>Primero basaremos nuestra explicación y construiremos el modelo utilizando RapidMiner, luego realizaremos los mismos pasos de selección y modelado en Python, para finalmente comparar ambos resultados y llegar a una conclusión.</app-paragraph>

<app-paragraph>¡Manos a la obra!</app-paragraph>

<app-sub-title>Entender el "negocio" y los datos.</app-sub-title>

<app-mini-sub-title>El "negocio"</app-mini-sub-title>

<app-paragraph>Cuando hablamos de entender el "negocio", nos referimos a comprender el problema/situación que estamos analizando. Para esto, puede ser muy útil hacer preguntas como:</app-paragraph>

<ul>
    <app-list-item>¿Qué problema traduce los datos?</app-list-item>
    <app-list-item>¿Entiendo el problema que estoy tratando de resolver?</app-list-item>
    <app-list-item>¿Qué representa mis datos?</app-list-item>
    <app-list-item>¿Qué quiero hacer/predict?</app-list-item>
</ul>

<app-paragraph>En este caso, dado que estamos trabajando en un problema/evento conocido, es fácil entender el "negocio". Nuestra intención es predecir la supervivencia de un individuo en la catástrofe del hundimiento del barco "Titanic", por lo que nos enfrentamos a un problema de clasificación (sobrevivir o no).</app-paragraph>

<app-mini-sub-title>Los datos</app-mini-sub-title>

<app-paragraph>Nuestro conjunto de datos actual representa en cada una de sus tuplas los datos de un pasajero, cada tupla tiene un total de 12 atributos que tienen diferentes tipos y dominios. Tenemos:</app-paragraph>

<ul>
    <app-list-item>PassengerId: Un identificador único dado a cada tupla del conjunto de datos. Tipo: numérico.</app-list-item>
    <app-list-item>Survived: Indica si el pasajero en cuestión sobrevivió o no. Tipo: binomial numérico con valor 1 (sobrevivió) o 0 (no sobrevivió) (esta es nuestra variable objetivo).</app-list-item>
    <app-list-item>Pclass: La clase en la que viajaba el pasajero. Tipo: numérico con 3 valores posibles, 1 (primera clase), 2 (segunda clase), 3 (tercera clase).</app-list-item>
    <app-list-item>Name: El nombre del pasajero. Tipo: categórico.</app-list-item>
    <app-list-item>Sex: El sexo del pasajero. Tipo: categórico binomial con valor "male" (si es masculino) o "female" (si es femenino).</app-list-item>
    <app-list-item>Age: La edad del pasajero. Tipo: numérico, entero.</app-list-item>
    <app-list-item>SibSp: El número de hermanos o cónyuges del pasajero a bordo. Tipo: numérico.</app-list-item>
    <app-list-item>Parch: El número de padres o hijos del pasajero a bordo. Tipo: numérico.</app-list-item>
    <app-list-item>Ticket11: El número de boleto del pasajero. Tipo: categórico.</app-list-item>
    <app-list-item>Fare: El precio del boleto pagado por el pasajero. Tipo: numérico.</app-list-item>
    <app-list-item>Cabin: El número de cabina del pasajero. Tipo: categórico.</app-list-item>
    <app-list-item>Embarked: El puerto donde el pasajero embarcó. Tipo: categórico con 3 valores posibles, "C" (Cherbourg), "Q" (Queenstown), "S" (Southampton).</app-list-item>
</ul>

<app-paragraph>Con todos los datos reconocidos, podemos hacer un análisis preliminar y proponer algunas hipótesis sobre su utilidad para predecir nuestra variable objetivo.</app-paragraph>

<app-paragraph>Por ejemplo, parece sensato decir que el nombre del pasajero no es un dato que proporcione mucha información para determinar su supervivencia. Por otro lado, parece que la edad o el sexo pueden desempeñar un papel, basándonos en la idea de "mujeres y niños primero en los botes".</app-paragraph>

<app-paragraph>Pero, al final del día, es cuando hagamos uso de tácticas de "limpieza" y selección de atributos que podremos saber de manera más confiable qué atributos tendrán cierto nivel de rendimiento cuando se apliquen por nuestro modelo.</app-paragraph>

<app-paragraph>Conociendo un poco sobre el contexto de nuestro problema, lo que queremos hacer y lo que tenemos actualmente, podemos proceder con nuestro proceso de modelado, la preparación de nuestros datos.</app-paragraph>

<app-paragraph>Cuando preparamos nuestros datos, es útil tener a mano esos problemas a los que debemos prestar atención, como:</app-paragraph>

<ul>
    <app-list-item>Presencia de valores *faltantes.</app-list-item>
    <app-list-item>Presencia de valores atípicos.</app-list-item>
    <app-list-item>La distribución de nuestros datos.</app-list-item>
    <app-list-item>La escala de nuestros datos.</app-list-item>
</ul>

<app-paragraph>Estos son solo algunos de los problemas más comunes a los que debemos prestar atención al preparar nuestros datos. Por supuesto, según el algoritmo o algoritmos que usemos y el problema que estemos tratando de resolver, seremos más o menos resistentes a la presencia de algunos de ellos, o daremos más o menos importancia a algunos de ellos (por ejemplo, en el caso de la detección de fraudes).</app-paragraph>

<app-paragraph>Vamos a RapidMiner y veamos la "calidad" de nuestro conjunto de datos.</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-1.png'"></app-image>

<app-paragraph>En primera instancia, podemos ver que el atributo "Cabin" tiene bastante información faltante. Por otro lado, "Age" también tiene algunos datos faltantes, pero en esta primera visualización parece ser mucho menos que "Cabin".</app-paragraph>

<app-paragraph>Si obtenemos las estadísticas de todos nuestros atributos, veremos que:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-2.png'"></app-image>

<app-paragraph>De hecho, hay algunos atributos con valores faltantes, más específicamente son:</app-paragraph>

<ul>
    <app-list-item>"Age" con 177 valores faltantes.</app-list-item>
    <app-list-item>"Cabin" con 687 valores faltantes.</app-list-item>
    <app-list-item>"Embarked" con 2 valores faltantes.</app-list-item>
</ul>

<app-paragraph>Por otro lado, si queremos analizar la presencia de valores atípicos, primero debemos determinar cuáles de los atributos actuales son candidatos para este tipo de problema. Por ejemplo, el atributo "Survived", que es binomial, no puede tener datos atípicos porque sus únicos valores posibles son 1 y 0, y en este caso esta característica se cumple, lo mismo sucede con el atributo "Pclass", por ejemplo.</app-paragraph>

<app-paragraph>Asimismo, el atributo que representa los nombres de los pasajeros ("Name") tampoco podrá tener datos atípicos, especialmente porque no es un dato numérico.</app-paragraph>

<app-paragraph>Si continuamos aplicando las mismas ideas para el resto de los datos, obtendremos que los candidatos a los que debemos prestar atención si buscamos valores atípicos son:</app-paragraph>

<ul>
    <app-list-item>"Age"</app-list-item>
    <app-list-item>"SibSp"</app-list-item>
    <app-list-item>"Parch"</app-list-item>
    <app-list-item>"Fare"</app-list-item>
</ul>

<app-paragraph>Entonces, habiendo obtenido esos datos, lo que debemos hacer ahora es analizarlos cuidadosamente. Una buena visualización inicial es observar los valores mínimo, máximo y promedio, así que seleccionando los atributos, obtenemos que:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-3.png'"></app-image>

<app-paragraph>Vemos que, por ejemplo, el atributo "Age", aunque tiene un valor máximo de 80, tiene un promedio de alrededor de 30, lo cual no está tan lejos. Además, podemos ver el mini gráfico de barras proporcionado que indica aproximadamente las edades más comunes, lo cual concuerda con los cálculos mencionados anteriormente, ya que podemos ver cómo la popularidad de los datos se centra entre los valores de 15-20 y ~40, mientras más alta sea la edad, menos ocurrencias de la misma hay. Podemos decir entonces que, aunque este atributo tiene datos un tanto alejados, no es una situación tan alarmante.</app-paragraph>

<app-paragraph>Por otro lado, si nos dirigimos a los atributos de "SibSp" y "Parch", que tienen un comportamiento similar entre ellos, vemos, gracias a los gráficos presentados, que la gran mayoría de los datos en los atributos están en el valor mínimo de 0, teniendo un máximo de 8 para el caso de "SibSp" y 6 para el caso de "Parch". Además, vemos que en general el valor promedio en ambos casos está muy lejos de los valores más altos, siendo el promedio de "SibSp" 0.523 y el de "Parch" 0.382. Aunque, aunque parece una llamada de atención, debemos tener en cuenta el significado de los datos. En este caso, como se mencionó anteriormente, estos atributos representan el número de pasajeros "relacionados" de alguna manera a cierto pasajero, lo cual debe tenerse en cuenta en el análisis final.</app-paragraph>

<app-paragraph>Finalmente, siendo el caso más diferenciador, obtenemos que el atributo "Fare" sí tiene valores atípicos. Decimos esto porque vemos que el valor mínimo en este caso es 0, mientras que el máximo es 512.329, siendo el promedio 32.204. Esto denota que el valor máximo de este atributo es un valor atípico. Además, si prestamos atención a los gráficos, también vemos que hay algunos datos con valores entre 200,000 y 300,000 que son considerablemente altos en comparación con la mayoría de los datos, que se encuentran entre 0 y 20,000. Así que concluimos que hay valores atípicos en este atributo, que tendremos que resolver.</app-paragraph>

<app-paragraph>Una herramienta muy útil para visualizar la distribución de nuestros datos son los gráficos, en este caso, si hacemos uso del gráfico "Scatter" podremos ver de una mejor manera los puntos que están más alejados de los valores populares. En lo siguiente aplicamos esta visualización para el atributo "Fare":</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-4.png'"></app-image>

<app-paragraph>Entonces vemos que hay algunos puntos (destacados en el recuadro rojo en la imagen) que están bastante lejos de los valores normales.</app-paragraph>

<app-paragraph>Además, si hacemos uso del operador "Detectar Valor Atípico" ofrecido por RapidMiner, podemos ver cómo se detectan los casos enmarcados en el cuadro:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-5.png'"></app-image>

<app-paragraph>Los puntos coloreados en verde son aquellos que fueron clasificados como "valores atípicos" (outliers), mientras que los azules son aquellos que no lo fueron (ten en cuenta que para el operador "Detectar Outliers", el parámetro que indica el número de "valores atípicos" a detectar se inicializó en 10, su valor predeterminado).</app-paragraph>

<app-paragraph>Este tipo de visualizaciones/herramientas nos ayuda a tener una determinación inicial del número de "valores atípicos", lo cual será muy útil al corregir este problema.</app-paragraph>

<app-paragraph>Lo mismo que hicimos con el atributo "Fare", podemos hacerlo con el resto de los atributos que consideramos, para determinar con más precisión la cantidad y presencia de "valores atípicos".</app-paragraph>

<app-paragraph>Estrechamente relacionado con el análisis de valores atípicos está el análisis de la distribución de nuestros datos. Algo de esto ya lo hemos estado discutiendo (sin mencionarlo explícitamente) cuando analizábamos, con los gráficos, la presencia de valores atípicos en los atributos:</app-paragraph>

<ul>
    <app-list-item>"Edad"</app-list-item>
    <app-list-item>"SibSp"</app-list-item>
    <app-list-item>"Parch"</app-list-item>
    <app-list-item>"Fare"</app-list-item>
</ul>

<app-paragraph>Debemos recordar que es beneficioso tener una distribución normal (Gaussiana) en nuestros datos, ya que podría afectar algunos modelos que eventualmente podríamos usar. Si analizamos algunas distribuciones de los atributos mencionados, con, por ejemplo, un histograma, veremos que en el caso de "Edad", sí tenemos una distribución más o menos normal:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-6.png'"></app-image>

<app-paragraph>Aunque no es perfecta, está cerca de lo que queremos.</app-paragraph>

<app-paragraph>Lo contrario ocurre con el atributo "Fare", que, como ya hemos visto, tiene una distribución bastante sesgada:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-7.png'"></app-image>

<app-paragraph>Esto debe tenerse en cuenta al usar nuestros datos, ya que podría afectar el rendimiento de algunos modelos, por lo que tendremos que considerar transformarlos.</app-paragraph>

<app-paragraph>Finalmente, otro punto a considerar es la escala en la que se encuentran nuestros datos, porque muchos algoritmos son sensibles a este punto, y si hay una escala desigual, el rendimiento podría verse afectado.</app-paragraph>

<app-paragraph>Una gran herramienta de visualización para ver la escala de nuestros datos es el gráfico "boxplot", de manera que al aplicarlo obtendremos:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-8.png'"></app-image>

<app-paragraph>A simple vista se nota que hay una distribución desigual en los atributos correspondientes (que son los numéricos), por lo que normalizarlos será un punto a considerar.</app-paragraph>

<app-sub-title>Conectando todos los puntos</app-sub-title>

<app-paragraph>Como resumen de todo lo que hemos estado hablando hasta ahora, podemos decir que:</app-paragraph>

<ul>
    <app-list-item>Valores faltantes: Si hay presencia de valores faltantes en los atributos "Edad", "Cabin", "Embarked".</app-list-item>
    <app-list-item>Valores atípicos: Si hay valores atípicos presentes, especialmente en los atributos "Fare", "SibSp", "Parch".</app-list-item>
    <app-list-item>Distribución: Atributos como "Fare", "SibSp", "Parch" presentan una distribución bastante marcada y no normal.</app-list-item>
    <app-list-item>Escala: Atributos numéricos "Edad", "SibSp", "Parch", "Fare" tienen escalas diferentes.</app-list-item>
</ul>

<app-sub-title>Preparando el conjunto de datos</app-sub-title>

<app-mini-sub-title>Valores faltantes</app-mini-sub-title>

<app-paragraph>En primer lugar, siempre es recomendable ocuparse de los valores faltantes. En la medida de lo posible, trataremos de evitar descartar tantos registros como sea posible, ya que los datos son un recurso muy limitado y demasiado importante.</app-paragraph>

<app-paragraph>Con esta premisa, para el caso de los valores faltantes del atributo "Edad", dado que son relativamente pocos (en comparación con el volumen total del conjunto de datos), lo que podemos hacer es utilizar una estrategia para imputar datos en estos registros. Una muy básica y bastante utilizada es reemplazar los faltantes por el promedio total del atributo.</app-paragraph>

<app-paragraph>Por otro lado, para el caso de "Embarked" que tiene solo 2 valores faltantes, podríamos reemplazarlos por el valor (o valores) más común (S).</app-paragraph>

<app-paragraph>Finalmente, tenemos el caso de "Cabin", el más complicado. "Cabin", como se mencionó anteriormente, tiene una gran cantidad de valores faltantes, de hecho, muy poco de los datos de este atributo tiene valores. En una situación como esta, donde no hay suficiente información para realizar ninguna transformación, lo más sensato sería descartar el uso de este atributo.</app-paragraph>

<app-paragraph>Sabiendo todo lo que tenemos que hacer, lo único que queda es ¡hacerlo! Así es como obtenemos en RapidMiner:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-9.png'"></app-image>

<app-callout>Ten en cuenta que la regla para el proceso es una regla de exclusión, y que excluimos el atributo "Passengerid" porque no es una pieza de datos que contribuya ninguna información a nuestro problema, es simplemente un identificador.</app-callout>

<app-paragraph>Ahora, para reemplazar los valores faltantes, lo que debemos hacer es:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-10.png'"></app-image>

<app-paragraph>El conjunto de datos resultante en este punto es:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-11.png'"></app-image>

<app-callout>
    <app-paragraph>Ten en cuenta que aunque el atributo "Embarked" no es numérico sino categórico, si aplicamos el reemplazo por promedio, el resultado será que los valores faltantes se reemplazarán por los datos más populares (S).</app-paragraph>
</app-callout>

<app-mini-sub-title>Valores atípicos</app-mini-sub-title>

<app-paragraph>Para corregir los valores atípicos, en este caso, que son pocos en número, lo que haremos es eliminar los registros que contienen tales datos. En este caso, el único atributo que vale la pena corregir es el atributo "Fare". Según el gráfico que obtuvimos anteriormente, lo ideal en este punto será filtrar todos los ejemplos que no parecen ser válidos, que son, a priori, aquellos por debajo de 400.00, de modo que tendremos un resultado similar al siguiente:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-12.png'"></app-image>

<app-paragraph>En este caso, se detectaron 3 tuplas que no se ajustaban al filtro indicado y se consideran valores atípicos.</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-13.png'"></app-image>

<app-mini-sub-title>Escalado de datos</app-mini-sub-title>

<app-paragraph>Finalmente, necesitamos ajustar la escala de ciertos atributos. Vimos que los atributos numéricos "<strong>Edad</strong>", "<u>SibSp</u>", "<u>Parch</u>", "<u>Fare</u>", tenían escalas diferentes, y esto puede ser perjudicial para algoritmos como k-nn, porque haría que ciertos atributos tengan una mayor influencia en las predicciones. Para resolver esto, debes normalizarlos, y en RapidMiner esto se puede hacer de la siguiente manera:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-14.png'"></app-image>

<app-paragraph>Obteniendo, en este caso, un resultado como el siguiente:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-15.png'"></app-image>

<app-paragraph>Ahora los datos tienen más o menos la misma escala, reduciendo la posible influencia de este problema en los algoritmos que usemos.</app-paragraph>

<app-callout>Observa que se utilizó la transformación predefinida "z-transformación".</app-callout>

<app-paragraph>En este punto, es importante aclarar que en el proceso final, la normalización no se realizará antes de aplicar una separación de datos para prueba y entrenamiento, o en cualquier caso antes de aplicar la validación cruzada. Más bien, se hará antes de estos procesos. Esto es para evitar la llamada "contaminación" de datos, donde nuestros modelos pueden contener información que no deberían, dándonos resultados engañosos.</app-paragraph>

<app-mini-sub-title>Finalizando la preparación</app-mini-sub-title>

<app-paragraph>En este punto, ya tenemos un conjunto de datos, a priori, mejor que el que teníamos al principio. Así que ahora lo único que queda es comenzar a probar esta versión de nuestros datos.</app-paragraph>

<app-sub-title>Modelado</app-sub-title>

<app-paragraph>Antes de comenzar el modelado, tenemos que reconocer ciertos pasos que debemos realizar, como:</app-paragraph>

<ul>
    <app-list-item>Determinar qué modelos serán más útiles para nosotros basándonos en nuestro tipo de problema.</app-list-item>
    <app-list-item>Determinar si usaremos alguna estrategia para mejorar tanto como sea posible el rendimiento de nuestro modelo.</app-list-item>
    <app-list-item>Determinar qué estrategia usaremos para evaluar el rendimiento de estos modelos.</app-list-item>
</ul>

<app-paragraph>Así que manos a la obra.</app-paragraph>

<app-mini-sub-title>Selección del modelo.</app-mini-sub-title>

<app-paragraph>Primero, antes de seleccionar cualquier modelo, debemos identificar el tipo de problema que tenemos, para determinar qué algoritmos podríamos usar en esta primera iteración. En este caso, como dijimos al principio de este trabajo, nos enfrentamos a un problema de clasificación binaria, ya que queremos determinar si una persona sobrevive o no.</app-paragraph>

<app-paragraph>Para resolver problemas de tipo clasificación, algunos algoritmos que pueden ser útiles son:</app-paragraph>

<ul>
    <app-list-item>Naive bayes: Siempre es un buen punto de partida para usar este modelo.</app-list-item>
    <app-list-item>Regresión logística: Modelo simple y útil en predicciones de dos clases.</app-list-item>
    <app-list-item>K-nn: Modelo simple que determina la distancia entre puntos para determinar a qué grupo pertenece un cierto registro.</app-list-item>
</ul>

<app-paragraph>Debe tenerse en cuenta que para cada uno de estos algoritmos será necesario realizar algunas modificaciones en los datos (tipos de datos, por ejemplo).</app-paragraph>

<app-mini-sub-title>Determinación de estrategias de rendimiento</app-mini-sub-title>

<app-paragraph>Tenemos algunas herramientas y estrategias que podemos usar para que nuestros modelos tengan el mejor rendimiento posible. Una de ellas se llama "Selección de Características", donde, basándonos en ciertos algoritmos, determinamos la mejor combinación posible de atributos para obtener mejores resultados.</app-paragraph>

<app-mini-sub-title>Evaluación del rendimiento</app-mini-sub-title>

<app-paragraph>Este punto es inevitable. Siempre querremos saber cómo se comporta nuestro modelo y qué tan bien hace lo que queremos que haga.</app-paragraph>

<app-paragraph>Existen varias estrategias que podemos usar para medir el rendimiento de un modelo, y algunas serán más o menos útiles que otras, dependiendo de nuestro caso particular. Para este trabajo, consideraremos dos posibles alternativas:</app-paragraph>

<ul>
    <app-list-item>Separar nuestro conjunto de datos para usar parte de los datos para entrenamiento y parte para pruebas.</app-list-item>
    <app-list-item>Hacer uso de la estrategia de validación cruzada.</app-list-item>
</ul>

<app-paragraph>Ambas alternativas son ampliamente utilizadas, la primera puede ser un poco más compleja de fijar porque hay problemas como: ¿Qué datos separar? ¿Cómo determino los datos a separar? ¿Obtuve un buen conjunto de prueba o entrenamiento? Entre otros. Así que esta vez haremos uso de la estrategia de validación cruzada.</app-paragraph>

<app-paragraph>¡Manos a la obra!</app-paragraph>

<app-paragraph>En primer lugar, lo que tenemos que hacer es asignar el papel de clase/variable objetivo al atributo "Survived", ya que es el que queremos predecir.</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-16.png'"></app-image>

<app-paragraph>Ahora, lo que tenemos que hacer es determinar qué estrategia usaremos para mejorar el rendimiento de nuestros modelos. Entre las que conocemos en este momento está la "Selección de Características", y entre las diferentes opciones que tenemos para aplicar esta estrategia, encontramos:</app-paragraph>

<ul>
    <app-list-item>Fuerza Bruta</app-list-item>
    <app-list-item>Selección Hacia Adelante</app-list-item>
    <app-list-item>Selección Hacia Atrás</app-list-item>
    <app-list-item>Evolutiva</app-list-item>
</ul>

<app-paragraph>Veremos las ventajas y desventajas de cada una de ellas para seleccionar la ideal:</app-paragraph>

<ul>
    <app-list-item><strong>Fuerza Bruta:</strong> Nos proporcionará las mejores combinaciones posibles de atributos, pero tendrá un retraso extremadamente alto porque probará todas las combinaciones posibles.</app-list-item>
    <app-list-item><strong>Selección Hacia Adelante:</strong> Es mucho mejor en términos de tiempo en comparación con la anterior, pero tiene la desventaja de que no estamos garantizados la mejor combinación posible.</app-list-item>
    <app-list-item><strong>Selección Hacia Atrás:</strong> En términos generales, es muy similar a la Selección Hacia Adelante.</app-list-item>
    <app-list-item><strong>Evolutiva:</strong> Algoritmo evolutivo, tiene mejores tiempos que la Fuerza Bruta y puede proporcionar mejores combinaciones que la Selección Hacia Adelante y Hacia Atrás. De lo anterior, en esta instancia parece que una optimización de tipo evolutiva es la mejor opción.</app-list-item>
</ul>

<app-paragraph>Llevemos todo lo anterior a RapidMiner:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-17.png'"></app-image>

<app-paragraph>Esta vez tenemos las tres operaciones de "Selección de Características", donde dentro de cada una hay una validación cruzada de la siguiente manera:</app-paragraph>

<app-image [image]="'../../../../../assets/titanic-18.png'"></app-image>

<app-sub-title>Evaluación</app-sub-title>

<app-paragraph>Es hora de determinar cuál de los modelos entrenados tiene el mejor rendimiento. Para esto, una táctica manual y básica, pero al mismo tiempo efectiva y simple, es comparar "a simple vista". Así que dados los siguientes resultados:</app-paragraph>

<app-mini-sub-title>Naive Bayes</app-mini-sub-title>

<app-image [image]="'../../../../../assets/titanic-20.png'"></app-image>

<app-mini-sub-title>Regresión Logística</app-mini-sub-title>

<app-image [image]="'../../../../../assets/titanic-21.png'"></app-image>

<app-mini-sub-title>K-NN</app-mini-sub-title>

<app-image [image]="'../../../../../assets/titanic-22.png'"></app-image>

<app-paragraph>Se puede decir que, de los algoritmos utilizados, K-NN es el que generó el mejor rendimiento.</app-paragraph>

<app-sub-title>Conclusiones</app-sub-title>

<app-paragraph>Como conclusiones, podemos decir que aunque esta es la primera iteración, los resultados a simple vista son, al menos, satisfactorios. Pero una cosa es segura, debemos seguir probando el modelo obtenido para explorar la posibilidad de mejorar el rendimiento.</app-paragraph>
